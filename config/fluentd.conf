# Fluentd configuration for log aggregation
# This configuration collects logs from various sources and forwards them to monitoring systems

<system>
  log_level info
  suppress_repeated_stacktrace true
</system>

# Input sources - collect logs from various sources
<source>
  @type tail
  path /app/logs/application.log
  pos_file /var/log/fluentd/application.log.pos
  tag credit-card.application
  format multiline
  format_firstline /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}/
  format1 /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) - (?<logger>\S+) - (?<level>\w+) - (?<filename>\S+):(?<line>\d+) - (?<function>\S+) - (?<message>.*)/
  time_format %Y-%m-%d %H:%M:%S
  time_key timestamp
</source>

<source>
  @type tail
  path /app/logs/errors.log
  pos_file /var/log/fluentd/errors.log.pos
  tag credit-card.errors
  format multiline
  format_firstline /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}/
  format1 /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) - (?<logger>\S+) - (?<level>\w+) - (?<filename>\S+):(?<line>\d+) - (?<function>\S+) - (?<message>.*)/
  time_format %Y-%m-%d %H:%M:%S
  time_key timestamp
</source>

<source>
  @type tail
  path /app/logs/security.log
  pos_file /var/log/fluentd/security.log.pos
  tag credit-card.security
  format /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) - SECURITY - (?<level>\w+) - (?<message>.*) - \[(?<location>.*)\]/
  time_format %Y-%m-%d %H:%M:%S
  time_key timestamp
</source>

<source>
  @type tail
  path /app/logs/performance.log
  pos_file /var/log/fluentd/performance.log.pos
  tag credit-card.performance
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S
</source>

<source>
  @type tail
  path /var/log/nginx/access.log
  pos_file /var/log/fluentd/nginx-access.log.pos
  tag credit-card.nginx.access
  format nginx
</source>

<source>
  @type tail
  path /var/log/nginx/error.log
  pos_file /var/log/fluentd/nginx-error.log.pos
  tag credit-card.nginx.error
  format /^(?<timestamp>\d{4}\/\d{2}\/\d{2} \d{2}:\d{2}:\d{2}) \[(?<level>\w+)\] (?<pid>\d+).(?<tid>\d+): (?<message>.*)/
  time_format %Y/%m/%d %H:%M:%S
  time_key timestamp
</source>

# Docker container logs (if running in Docker)
<source>
  @type tail
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/fluentd/docker.log.pos
  tag docker.*
  format json
  time_key time
  time_format %Y-%m-%dT%H:%M:%S.%NZ
</source>

# Add common fields to all logs
<filter credit-card.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    service_name credit-card-processor
    environment "#{ENV['ENVIRONMENT'] || 'production'}"
    version "#{ENV['VERSION'] || '1.0.0'}"
  </record>
</filter>

# Add severity levels for alerting
<filter credit-card.errors>
  @type record_transformer
  <record>
    severity critical
    alert_required true
  </record>
</filter>

<filter credit-card.security>
  @type record_transformer
  <record>
    severity high
    alert_required true
  </record>
</filter>

# Performance metrics processing
<filter credit-card.performance>
  @type record_transformer
  enable_ruby true
  <record>
    # Extract numeric metrics for monitoring
    response_time_numeric ${record['message'].match(/response_time:(\d+\.?\d*)/)[1] rescue nil}
    error_rate_numeric ${record['message'].match(/error_rate:(\d+\.?\d*)/)[1] rescue nil}
  </record>
</filter>

# Output destinations - configure based on your monitoring stack

# Send to Elasticsearch (if using ELK stack)
# <match credit-card.**>
#   @type elasticsearch
#   host elasticsearch.example.com
#   port 9200
#   index_name credit-card-processor
#   type_name _doc
#   include_timestamp true
#   reconnect_on_error true
#   reload_on_failure true
#   reload_connections false
#   <buffer>
#     @type file
#     path /var/log/fluentd/elasticsearch
#     flush_mode interval
#     flush_interval 10s
#     chunk_limit_size 10MB
#     queue_limit_length 32
#     retry_max_interval 30
#     retry_forever true
#   </buffer>
# </match>

# Send to Splunk (if using Splunk)
# <match credit-card.**>
#   @type splunk_hec
#   protocol https
#   hec_host splunk.example.com
#   hec_port 8088
#   hec_token YOUR_HEC_TOKEN
#   index credit-card-processor
#   source fluentd
#   sourcetype json
#   <buffer>
#     @type file
#     path /var/log/fluentd/splunk
#     flush_mode interval
#     flush_interval 10s
#     chunk_limit_size 10MB
#   </buffer>
# </match>

# Send to CloudWatch (if using AWS)
# <match credit-card.**>
#   @type cloudwatch_logs
#   region us-east-1
#   log_group_name /aws/ecs/credit-card-processor
#   log_stream_name_key hostname
#   auto_create_stream true
#   <buffer>
#     flush_interval 10s
#     chunk_limit_size 2m
#     queued_chunks_limit_size 32
#   </buffer>
# </match>

# Local file output for testing/backup
<match credit-card.**>
  @type file
  path /var/log/fluentd/aggregated/credit-card
  append true
  <format>
    @type json
  </format>
  <buffer time>
    @type file
    path /var/log/fluentd/buffer/credit-card
    timekey 3600  # 1 hour
    timekey_wait 1m
    flush_mode interval
    flush_interval 10s
  </buffer>
</match>

# Error handling - capture any unmatched logs
<match **>
  @type file
  path /var/log/fluentd/unmatched/unmatched
  append true
  <format>
    @type json
  </format>
  <buffer>
    flush_interval 30s
  </buffer>
</match>