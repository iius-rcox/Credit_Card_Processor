name: Comprehensive Test Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'

jobs:
  # Backend Unit Tests
  backend-unit-tests:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: credit_card_processor_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install Python dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install coverage pytest-cov pytest-xvfb
    
    - name: Set up test environment
      run: |
        cd backend
        cp .env.test.example .env.test
        python -m pytest --version
    
    - name: Run backend unit tests with coverage
      run: |
        cd backend
        python -m pytest tests/ \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=80 \
          --junitxml=test-results.xml \
          -v
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/credit_card_processor_test
        TESTING: true
    
    - name: Upload backend coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        files: ./backend/coverage.xml
        flags: backend
        name: backend-coverage
    
    - name: Upload backend test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: backend-test-results
        path: |
          backend/test-results.xml
          backend/htmlcov/
          backend/coverage.xml

  # Frontend Unit Tests
  frontend-unit-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci
    
    - name: Lint frontend code
      run: |
        cd frontend
        npm run lint || true  # Don't fail on lint errors for now
    
    - name: Run frontend unit tests with coverage
      run: |
        cd frontend
        npm run test:coverage -- --reporter=verbose --reporter=junit
      env:
        NODE_ENV: test
    
    - name: Upload frontend coverage to Codecov  
      uses: codecov/codecov-action@v3
      with:
        files: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage
    
    - name: Upload frontend test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: frontend-test-results
        path: |
          frontend/coverage/
          frontend/test-results.xml

  # Security Tests
  security-tests:
    runs-on: ubuntu-latest
    needs: [backend-unit-tests, frontend-unit-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run npm audit
      run: |
        npm audit --audit-level=moderate || true
        cd frontend && npm audit --audit-level=moderate || true
        cd ../backend && pip-audit || true
    
    - name: Run security linting
      run: |
        npx eslint . --ext .js,.vue --config .eslintrc.security.js || true
    
    - name: OWASP ZAP Baseline Scan
      uses: zaproxy/action-baseline@v0.7.0
      with:
        target: 'http://localhost:3000'
        rules_file_name: '.zap/rules.tsv'
        cmd_options: '-a'
      continue-on-error: true

  # Integration Tests with Docker
  integration-tests:
    runs-on: ubuntu-latest
    needs: [backend-unit-tests, frontend-unit-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build application with Docker Compose
      run: |
        cp .env.test.example .env
        docker-compose -f docker-compose.yml -f docker-compose.test.yml build
    
    - name: Start services
      run: |
        docker-compose -f docker-compose.yml -f docker-compose.test.yml up -d
        sleep 30  # Wait for services to be ready
    
    - name: Wait for services to be healthy
      run: |
        timeout 300 bash -c 'until curl -f http://localhost:8001/health; do sleep 5; done'
        timeout 300 bash -c 'until curl -f http://localhost:3000; do sleep 5; done'
    
    - name: Run backend integration tests
      run: |
        docker-compose exec -T backend python -m pytest tests/integration/ -v
      continue-on-error: true
    
    - name: Check application logs
      if: always()
      run: |
        docker-compose logs backend
        docker-compose logs frontend
    
    - name: Cleanup
      if: always()
      run: |
        docker-compose down -v
        docker system prune -f

  # End-to-End Tests
  e2e-tests:
    runs-on: ubuntu-latest
    needs: [integration-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Install Playwright browsers
      run: npx playwright install --with-deps
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Start application services
      run: |
        cp .env.test.example .env
        docker-compose up -d
        sleep 45  # Extended wait for full application startup
    
    - name: Wait for application readiness
      run: |
        timeout 300 bash -c 'until curl -f http://localhost:8001/health; do sleep 5; done'
        timeout 300 bash -c 'until curl -f http://localhost:3000; do sleep 5; done'
    
    - name: Run comprehensive E2E tests
      run: |
        npx playwright test tests/e2e-comprehensive/ \
          --reporter=html \
          --reporter=junit \
          --timeout=120000
      env:
        PLAYWRIGHT_BASE_URL: http://localhost:3000
        API_BASE_URL: http://localhost:8001
    
    - name: Run security E2E tests
      run: |
        npx playwright test tests/security/ \
          --reporter=html \
          --reporter=junit \
          --timeout=60000
      continue-on-error: true
    
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: |
          playwright-report/
          test-results/
    
    - name: Upload E2E screenshots and videos
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: e2e-failures
        path: |
          test-results/
          playwright-report/
    
    - name: Cleanup E2E environment
      if: always()
      run: |
        docker-compose down -v
        docker system prune -f

  # Performance Tests
  performance-tests:
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[perf]')
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install performance testing tools
      run: |
        pip install locust pytest-benchmark
        npm install -g lighthouse artillery
    
    - name: Start application
      run: |
        cp .env.test.example .env
        docker-compose up -d
        sleep 45
    
    - name: Wait for application readiness
      run: |
        timeout 300 bash -c 'until curl -f http://localhost:8001/health; do sleep 5; done'
        timeout 300 bash -c 'until curl -f http://localhost:3000; do sleep 5; done'
    
    - name: Run load tests with Locust
      run: |
        cd tests/performance
        locust -f locustfile.py --host=http://localhost:8001 \
          --users 50 --spawn-rate 5 --run-time 5m \
          --html load-test-report.html --csv load-test
      continue-on-error: true
    
    - name: Run Lighthouse performance audit
      run: |
        lighthouse http://localhost:3000 \
          --output-path=lighthouse-report.html \
          --output=html \
          --chrome-flags="--headless --no-sandbox"
      continue-on-error: true
    
    - name: Upload performance test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: |
          tests/performance/load-test-report.html
          tests/performance/load-test_*.csv
          lighthouse-report.html
    
    - name: Cleanup performance test environment
      if: always()
      run: |
        docker-compose down -v

  # Database Migration Tests
  database-migration-tests:
    runs-on: ubuntu-latest
    needs: [backend-unit-tests]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: credit_card_processor_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
    
    - name: Test database migrations
      run: |
        cd backend
        alembic upgrade head
        alembic downgrade base
        alembic upgrade head
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/credit_card_processor_test

  # Code Quality and Analysis
  code-quality:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better analysis
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        npm ci
        cd frontend && npm ci
        cd ../backend && pip install -r requirements.txt
        pip install flake8 black isort mypy
    
    - name: Run Python code quality checks
      run: |
        cd backend
        flake8 app/ --max-line-length=88 --extend-ignore=E203,W503
        black app/ --check --diff
        isort app/ --check --diff
        mypy app/ --ignore-missing-imports
      continue-on-error: true
    
    - name: Run JavaScript/Vue code quality checks  
      run: |
        cd frontend
        npm run lint
        npm run format:check || true
      continue-on-error: true
    
    - name: SonarCloud Scan
      uses: SonarSource/sonarcloud-github-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      continue-on-error: true

  # Deployment Readiness Check
  deployment-readiness:
    runs-on: ubuntu-latest
    needs: [backend-unit-tests, frontend-unit-tests, integration-tests, e2e-tests, security-tests]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build production images
      run: |
        docker build -f backend/Dockerfile.prod -t credit-card-processor-backend:latest ./backend
        docker build -f frontend/Dockerfile.prod -t credit-card-processor-frontend:latest ./frontend
    
    - name: Test production image startup
      run: |
        docker run -d --name backend-prod -p 8001:8001 \
          -e DATABASE_URL=sqlite:///./test.db \
          credit-card-processor-backend:latest
        
        docker run -d --name frontend-prod -p 3000:3000 \
          credit-card-processor-frontend:latest
        
        sleep 30
        
        # Test if services are responding
        curl -f http://localhost:8001/health
        curl -f http://localhost:3000
        
        docker stop backend-prod frontend-prod
        docker rm backend-prod frontend-prod
    
    - name: Vulnerability scan on production images
      run: |
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          aquasec/trivy:latest image credit-card-processor-backend:latest
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          aquasec/trivy:latest image credit-card-processor-frontend:latest
      continue-on-error: true

  # Test Results Summary
  test-summary:
    runs-on: ubuntu-latest
    needs: [backend-unit-tests, frontend-unit-tests, integration-tests, e2e-tests, security-tests, code-quality]
    if: always()
    
    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate test summary
      run: |
        echo "# Test Results Summary" > test-summary.md
        echo "" >> test-summary.md
        
        echo "## Backend Unit Tests" >> test-summary.md
        if [ -f "backend-test-results/test-results.xml" ]; then
          echo "✅ Backend unit tests completed" >> test-summary.md
        else
          echo "❌ Backend unit tests failed" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "## Frontend Unit Tests" >> test-summary.md
        if [ -f "frontend-test-results/test-results.xml" ]; then
          echo "✅ Frontend unit tests completed" >> test-summary.md
        else
          echo "❌ Frontend unit tests failed" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "## E2E Tests" >> test-summary.md
        if [ -d "e2e-test-results" ]; then
          echo "✅ E2E tests completed" >> test-summary.md
        else
          echo "❌ E2E tests failed" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "## Security Tests" >> test-summary.md
        echo "🔍 Security tests executed (check individual results)" >> test-summary.md
        
        cat test-summary.md
    
    - name: Comment test summary on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('test-summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });
    
    - name: Upload test summary
      uses: actions/upload-artifact@v3
      with:
        name: test-summary
        path: test-summary.md

# Scheduled maintenance and cleanup
  cleanup-test-data:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - name: Cleanup old test artifacts
      uses: geekyeggo/delete-artifact@v2
      with:
        name: |
          backend-test-results
          frontend-test-results
          e2e-test-results
          performance-test-results
        failOnError: false
        
    - name: Cleanup Docker resources
      run: |
        docker system prune -af
        docker volume prune -f